{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import pickle\n",
    "\n",
    "markers = ['o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X']\n",
    "colors = [\n",
    "    '#377eb8',\n",
    "    '#e41a1c',\n",
    "    '#4daf4a',\n",
    "    '#984ea3',\n",
    "    '#ff7f00',\n",
    "    '#ffff33',\n",
    "    '#a65628',\n",
    "    '#f781bf',\n",
    "    '#999999',\n",
    "]\n",
    "\n",
    "graph_names = [\n",
    "    # social\n",
    "    'OF',\n",
    "    'openflights',\n",
    "    # hypergraphs\n",
    "    'coauth-DBLP-proj-graph',\n",
    "    'coauth-MAG-Geology-proj-graph',\n",
    "    'threads-ask-ubuntu-proj-graph',\n",
    "    'threads-math-sx-proj-graph',\n",
    "    'threads-stack-overflow-proj-graph',\n",
    "    # temporal\n",
    "    'sx-askubuntu',\n",
    "    'sx-mathoverflow',\n",
    "    'sx-stackoverflow',\n",
    "    'sx-superuser',\n",
    "]\n",
    "\n",
    "graph_names_short = [\n",
    "    # social\n",
    "    'OF',\n",
    "    'FL',\n",
    "    # hypergraphs\n",
    "    'co-DB',\n",
    "    'co-GE',\n",
    "    'th-UB',\n",
    "    'th-MA',\n",
    "    'th-SO',\n",
    "    # temporal\n",
    "    'sx-UB',\n",
    "    'sx-MA',\n",
    "    'sx-SO',\n",
    "    'sx-SU',\n",
    "]\n",
    "\n",
    "name2nameShort = dict(zip(graph_names, graph_names_short))\n",
    "\n",
    "g2fitting = {\n",
    "    # social\n",
    "    'OF': 1,\n",
    "    'openflights': 2,\n",
    "    # hypergraphs\n",
    "    'coauth-DBLP-proj-graph': 3,\n",
    "    'coauth-MAG-Geology-proj-graph': 3,\n",
    "    'threads-ask-ubuntu-proj-graph': 1,\n",
    "    'threads-math-sx-proj-graph': 1,\n",
    "    'threads-stack-overflow-proj-graph': 1,\n",
    "    # temporal\n",
    "    'sx-askubuntu': 2,\n",
    "    'sx-mathoverflow': 2,\n",
    "    'sx-stackoverflow': 2,\n",
    "    'sx-superuser': 2,\n",
    "}\n",
    "\n",
    "g2nm = {\n",
    "    'OF': (897, 71380),\n",
    "    'openflights': (2905, 15645),\n",
    "\n",
    "    'coauth-DBLP-proj-graph': (1654109, 7713116),\n",
    "    'coauth-MAG-Geology-proj-graph': (898648, 4891112),\n",
    "    'threads-ask-ubuntu-proj-graph': (82075, 182648),\n",
    "    'threads-math-sx-proj-graph': (152702, 1088735),\n",
    "    'threads-stack-overflow-proj-graph': (2301070, 20989078),\n",
    "\n",
    "    'sx-askubuntu': (152599, 453221),\n",
    "    'sx-mathoverflow': (24668, 187939),\n",
    "    'sx-stackoverflow': (2572345, 28177464),\n",
    "    'sx-superuser': (189191, 712870),\n",
    "}\n",
    "\n",
    "gt_c_star_wt1 = {\n",
    "    'OF': 241,\n",
    "    'openflights': 64,\n",
    "\n",
    "    'coauth-DBLP-proj-graph': 83,\n",
    "    'coauth-MAG-Geology-proj-graph': 74,\n",
    "    'threads-ask-ubuntu-proj-graph': 73,\n",
    "    'threads-math-sx-proj-graph': 372,\n",
    "    'threads-stack-overflow-proj-graph': 685,\n",
    "\n",
    "    'sx-askubuntu': 152,\n",
    "    'sx-mathoverflow': 185,\n",
    "    'sx-stackoverflow': 886,\n",
    "    'sx-superuser': 202,\n",
    "}\n",
    "\n",
    "gt_c_star_more = {\n",
    "    'OF': [(241, 271), (190, 192), (157, 156), (134, 137), (119, 101)],\n",
    "    'openflights': [(64, 66), (31, 31), (17, 17), (None, None), (None, None)],\n",
    "    'coauth-DBLP-proj-graph': [(83, 88), (36, 29), (22, 24), (20, 21), (16, 16)],\n",
    "    'coauth-MAG-Geology-proj-graph': [(74, 92), (52, 49), (34, 40), (28, 30), (24, 21)],\n",
    "    'threads-ask-ubuntu-proj-graph': [(73, 87), (30, 31), (19, 20), (18, 11), (15, 11)],\n",
    "    'threads-math-sx-proj-graph': [(372, 401), (145, 153), (114, 114), (84, 67), (63, 59)],\n",
    "    'threads-stack-overflow-proj-graph': [(685, 750), (208, 205), (134, 129), (97, 82), (74, 72)],\n",
    "    'sx-askubuntu': [(152, 149), (63, 69), (48, 42), (36, 27), (31, 22)],\n",
    "    'sx-mathoverflow': [(185, 181), (113, 102), (75, 63), (60, 49), (51, 41)],\n",
    "    'sx-stackoverflow': [(886, 749), (407, 324), (221, 203), (169, 130), (120, 103)],\n",
    "    'sx-superuser': [(202, 206), (96, 93), (63, 54), (48, 37), (36, 27)],\n",
    "}\n",
    "\n",
    "p_data = Path(f'data')\n",
    "p_data.mkdir(exist_ok=True)\n",
    "\n",
    "p_results = Path('results')\n",
    "p_results.mkdir(exist_ok=True)\n",
    "\n",
    "Edge = tuple[int, int]\n",
    "EdgeAndWeight = tuple[int, int, int]\n",
    "graphs_sorted_m = sorted(graph_names, key=lambda xx: g2nm[xx][1])\n",
    "\n",
    "\n",
    "def iter_edges(input_graph, with_weight=False, desc='edges'):\n",
    "    return tqdm(input_graph.edges.data('weight', default=1) if with_weight else input_graph.edges,\n",
    "                total=input_graph.number_of_edges(), leave=False, desc=desc)\n",
    "\n",
    "\n",
    "def iter_nodes(input_graph, desc='nodes'):\n",
    "    return tqdm(input_graph.nodes, total=input_graph.number_of_nodes(), leave=False, desc=desc)\n",
    "\n",
    "\n",
    "def data_exist(ds, data_name_, layer_index=None):\n",
    "    if layer_index is not None:\n",
    "        return (p_data / data_name_ / f'{ds}.{data_name_}_layer{layer_index}').is_file()\n",
    "    return (p_data / data_name_ / f'{ds}.{data_name_}').is_file()\n",
    "\n",
    "\n",
    "def data_file_path(ds, data_name_, layer_index=None, write=False):\n",
    "    if write:\n",
    "        (p_data / data_name_).mkdir(exist_ok=True)\n",
    "        mode = 'wb'\n",
    "    else:\n",
    "        mode = 'rb'\n",
    "    if layer_index is not None:\n",
    "        return p_data / data_name_ / f'{ds}.{data_name_}_layer{layer_index}', mode\n",
    "    return p_data / data_name_ / f'{ds}.{data_name_}', mode\n",
    "\n",
    "\n",
    "def save_data(data, ds, data_name_, layer_index=None):\n",
    "    with open(*data_file_path(ds, data_name_, write=True, layer_index=layer_index)) as f_:\n",
    "        pickle.dump(data, f_)\n",
    "\n",
    "\n",
    "def load_data(ds, data_name_, layer_index=None):\n",
    "    with open(*data_file_path(ds, data_name_, write=False, layer_index=layer_index)) as f_:\n",
    "        return pickle.load(f_)\n",
    "\n",
    "\n",
    "def min_max_tuple(xx, yy):\n",
    "    return min(xx, yy), max(xx, yy)\n",
    "\n",
    "\n",
    "def reorder_nodes(input_graph):\n",
    "    return nx.convert_node_labels_to_integers(input_graph)\n",
    "\n",
    "\n",
    "def take_gcc(input_graph):\n",
    "    return input_graph.subgraph(max(nx.connected_components(input_graph), key=len))\n",
    "\n",
    "p = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "# read the raw data and convert it into graphs\n",
    "# saving edge text file, edges, weights, and edges-and-weights lists\n",
    "p['raw_data'] = Path('raw_data')\n",
    "assert p['raw_data'].is_dir()\n",
    "data_names = [\n",
    "    'graph',\n",
    "    'edge_txt',\n",
    "    'edges',\n",
    "    'weights',\n",
    "    'edges_and_weights',\n",
    "    'neighbors_list',\n",
    "    'number_of_CNs_list',\n",
    "]\n",
    "for data_name in data_names:\n",
    "    p[data_name] = p_data / data_name\n",
    "    p[data_name].mkdir(exist_ok=True)\n",
    "\n",
    "for f_raw_data in p['raw_data'].iterdir():\n",
    "    graph_name = [name_ for name_ in graph_names if name_ in f_raw_data.name][0]\n",
    "    G = nx.Graph()\n",
    "    with f_raw_data.open() as f:\n",
    "        dd = f.readlines()\n",
    "    for d in dd:\n",
    "        u, v, w = map(int, d.split())\n",
    "        G.add_edge(u, v, weight=w)\n",
    "    G = take_gcc(G)\n",
    "    G = reorder_nodes(G)\n",
    "    save_data(G, graph_name, 'graph')\n",
    "    print(graph_name, G)\n",
    "    n, m = g2nm[graph_name]\n",
    "    assert (n, m) == (G.number_of_nodes(), G.number_of_edges())\n",
    "    neighbors_list = [set(G[v]) for v in range(n)]\n",
    "    edges = []\n",
    "    weights = []\n",
    "    edges_and_weights = []\n",
    "    number_of_CNs_list = []\n",
    "    with (p['edge_txt'] / f'{graph_name}.edge_txt').open('w+') as f:\n",
    "        for u, v, w in iter_edges(G, with_weight=True, desc=graph_name):\n",
    "            u, v = min_max_tuple(u, v)\n",
    "            edges.append((u, v))\n",
    "            weights.append(w)\n",
    "            edges_and_weights.append((u, v, w))\n",
    "            cn_uv = len(neighbors_list[u] & neighbors_list[v])\n",
    "            number_of_CNs_list.append(cn_uv)\n",
    "            f.write(f'{u} {v} {w}\\n')\n",
    "    save_data(neighbors_list, graph_name, 'neighbors_list')\n",
    "    save_data(edges, graph_name, 'edges')\n",
    "    save_data(weights, graph_name, 'weights')\n",
    "    save_data(edges_and_weights, graph_name, 'edges_and_weights')\n",
    "    save_data(number_of_CNs_list, graph_name, 'number_of_CNs_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# number of common neighbors c -> number of pairs sharing c CNs\n",
    "# for each dataset, among all the node pairs, for each number c of common neighbors,\n",
    "# we compute how many pairs share c CNs\n",
    "# we use the cpp program cn_pairs.cpp\n",
    "\n",
    "cmd_compile = ['g++', '-O3', '-std=c++2a', 'cn_pairs.cpp', '-o', 'cn_pairs', '-lpthread']\n",
    "subprocess.run(cmd_compile)\n",
    "for graph_name in graphs_sorted_m:\n",
    "    print(graph_name)\n",
    "    cmd_run = ['./cn_pairs', name2nameShort[graph_name]]\n",
    "    subprocess.run(cmd_run)\n",
    "    # string outfile = \"data/numberOfCN2numberOfPairs_cpp/\" + dataset_full + \".txt\";\n",
    "    with open(p_data / f'numberOfCN2numberOfPairs_cpp/{graph_name}.txt') as f:\n",
    "        dd = f.readlines()\n",
    "    cn2p = dict()\n",
    "    for d in dd:\n",
    "        try:\n",
    "            cn, p = map(int, d.split())\n",
    "            cn2p[cn] = p\n",
    "        except:\n",
    "            continue\n",
    "    save_data(cn2p, graph_name, f'numberOfCN2numberOfPairs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make the layers\n",
    "data_names = [\n",
    "    'layers'\n",
    "]\n",
    "for data_name in data_names:\n",
    "    p[data_name] = p_data / data_name\n",
    "    p[data_name].mkdir(exist_ok=True)\n",
    "\n",
    "for graph_name in graphs_sorted_m:\n",
    "    G = load_data(graph_name, 'graph')\n",
    "    n, m = g2nm[graph_name]\n",
    "    weights = load_data(graph_name, 'weights')\n",
    "    edges_and_weights = load_data(graph_name, 'edges_and_weights')\n",
    "    w_max = max(weights)\n",
    "    for i_layer in trange(2, min(w_max, 10) + 1):\n",
    "        edges_and_weights = [(u, v, w) for u, v, w in edges_and_weights if w >= i_layer]\n",
    "        G_i = nx.Graph()\n",
    "        for u, v, w in edges_and_weights:\n",
    "            G_i.add_edge(u, v, weight=w)\n",
    "        save_data(G_i, graph_name, 'layers', layer_index=i_layer)\n",
    "        print(graph_name, f'layer{i_layer}', G_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# number of common neighbors c -> number of pairs sharing c CNs for the layers\n",
    "# we use the cpp program cn_pairs_layers.cpp\n",
    "\n",
    "# string edge_input = \"data/edge_txt_layers/\" + dataset_full + \"_layer\" + to_string(i_layer) + \".edge_txt\";\n",
    "data_names = [\n",
    "    'edge_txt_layers'\n",
    "]\n",
    "for data_name in data_names:\n",
    "    p[data_name] = p_data / data_name\n",
    "    p[data_name].mkdir(exist_ok=True)\n",
    "\n",
    "cmd_compile = ['g++', '-O3', '-std=c++2a', 'cn_pairs_layers.cpp', '-o', 'cn_pairs_layers', '-lpthread']\n",
    "subprocess.run(cmd_compile)\n",
    "\n",
    "for graph_name in graphs_sorted_m:\n",
    "    print(graph_name)\n",
    "    n, m = g2nm[graph_name]\n",
    "    weights = load_data(graph_name, 'weights')\n",
    "    w_max = max(weights)\n",
    "    for i_layer in trange(2, min(w_max, 5) + 1):\n",
    "        G_i = load_data(graph_name, 'layers', layer_index=i_layer)\n",
    "        print(graph_name, f'layer{i_layer}', G_i)\n",
    "        G_i = reorder_nodes(G_i)\n",
    "        n_i, m_i = G_i.number_of_nodes(), G_i.number_of_edges()\n",
    "        with open(p['edge_txt_layers'] / f'{graph_name}_layer{i_layer}.edge_txt', 'w+') as f:\n",
    "            f.write(f'{n} {m}\\n')\n",
    "            for u, v in iter_edges(G_i):\n",
    "                f.write(f'{u} {v}\\n')\n",
    "            cmd_run = ['./cn_pairs_layers', name2nameShort[graph_name], str(i_layer)]\n",
    "            subprocess.run(cmd_run)\n",
    "        with open(p_data / f'numberOfCN2numberOfPairs_cpp/{graph_name}_layer{i_layer}.txt') as f:\n",
    "            dd = f.readlines()\n",
    "        cn2p = dict()\n",
    "        for d in dd:\n",
    "            try:\n",
    "                cn, p = map(int, d.split())\n",
    "                cn2p[cn] = p\n",
    "            except:\n",
    "                continue\n",
    "        save_data(cn2p, graph_name, f'numberOfCN2numberOfPairs_layers', layer_index=i_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "\n",
    "# metrics\n",
    "metrics = [\n",
    "    'CN',\n",
    "    'SA',\n",
    "    'JC',\n",
    "    'HP',\n",
    "    'HD',\n",
    "    'SI',\n",
    "    'LI',\n",
    "    'AA',\n",
    "    'RA',\n",
    "    'PA',\n",
    "    'FM',\n",
    "    'DL',\n",
    "]\n",
    "data_names = [\n",
    "    f'{metric}-list' for metric in metrics\n",
    "]\n",
    "for data_name in data_names:\n",
    "    p[data_name] = p_data / data_name\n",
    "    p[data_name].mkdir(exist_ok=True)\n",
    "\n",
    "for graph_name in graphs_sorted_m:\n",
    "    edges = load_data(graph_name, 'edges')\n",
    "    neighbors_list = load_data(graph_name, 'neighbors_list')\n",
    "    metric2list = defaultdict(list)\n",
    "    degrees = [len(N) for N in neighbors_list]\n",
    "    for u, v in tqdm(edges, desc=graph_name, leave=False):\n",
    "        Nu, Nv = neighbors_list[u], neighbors_list[v]\n",
    "        du, dv = len(Nu), len(Nv)\n",
    "        metric2value = defaultdict(float)\n",
    "        CN_uv = Nu & Nv\n",
    "        cn_uv = len(CN_uv)\n",
    "        metric2value['CN'] = cn_uv\n",
    "        metric2value['SA'] = cn_uv / math.sqrt(du * dv)\n",
    "        metric2value['JC'] = cn_uv / (du + dv - cn_uv)\n",
    "        metric2value['HP'] = cn_uv / min(du, dv)\n",
    "        metric2value['HD'] = cn_uv / max(du, dv)\n",
    "        metric2value['SI'] = cn_uv / (du + dv)\n",
    "        metric2value['LI'] = cn_uv / (du * dv)\n",
    "        for x in CN_uv:\n",
    "            metric2value['AA'] += 1 / math.log(degrees[x])\n",
    "            metric2value['RA'] += 1 / degrees[x]\n",
    "        metric2value['PA'] = du * dv\n",
    "        metric2value['FM'] = cn_uv\n",
    "        for x, y in product(Nu - Nv, Nv - Nu):\n",
    "            if y in neighbors_list[x]:\n",
    "                metric2value['FM'] += 1\n",
    "        metric2value['DL'] = du + dv - 2\n",
    "        for metric in metrics:\n",
    "            metric2list[metric].append(metric2value[metric])\n",
    "    for metric, metric_list in metric2list.items():\n",
    "        save_data(metric_list, graph_name, f'{metric}-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# metric (using cpp)\n",
    "# you may run the cpp version of the above cell (metrics.cpp) for higher speed\n",
    "# this cell will run the cpp program and read the output\n",
    "\n",
    "# you can change the variable \"graph_names_large\"\n",
    "# for changing the range of the datasets\n",
    "# on which the cpp program runs\n",
    "metrics = [\n",
    "    'CN',\n",
    "    'SA',\n",
    "    'JC',\n",
    "    'HP',\n",
    "    'HD',\n",
    "    'SI',\n",
    "    'LI',\n",
    "    'AA',\n",
    "    'RA',\n",
    "    'PA',\n",
    "    'FM',\n",
    "    'DL',\n",
    "]\n",
    "data_names = [\n",
    "    f'{metric}-list' for metric in metrics\n",
    "]\n",
    "for data_name in data_names:\n",
    "    p[data_name] = p_data / data_name\n",
    "    p[data_name].mkdir(exist_ok=True)\n",
    "\n",
    "graph_names_large = graphs_sorted_m[-6:]\n",
    "# compile the cpp file\n",
    "cmd_compile = ['g++', '-O3', '-std=c++2a', 'metrics.cpp', '-o', 'metric', '-lpthread']\n",
    "subprocess.run(cmd_compile)\n",
    "for graph_name in graph_names_large:\n",
    "    print(graph_name)\n",
    "    cmd_run = ['./metric', name2nameShort[graph_name]]\n",
    "    subprocess.run(cmd_run)\n",
    "    for metric in metrics:\n",
    "        metric_list = []\n",
    "        with open(p_data / f'metrics_cpp/{graph_name}_{metric.lower()}.txt') as f:\n",
    "            dd = f.readlines()\n",
    "        for d in dd:\n",
    "            try:\n",
    "                data_float = float(d)\n",
    "                metric_list.append(data_float)\n",
    "            except:\n",
    "                continue\n",
    "        save_data(metric_list, graph_name, f'{metric}-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sknetwork.topology import CoreDecomposition\n",
    "\n",
    "# edge coreness\n",
    "\n",
    "metric_names = [\n",
    "    'coreness_list',\n",
    "    'edge_coreness_list',\n",
    "]\n",
    "\n",
    "for graph_name in graphs_sorted_m:\n",
    "    n, m = g2nm[graph_name]\n",
    "    G = load_data(graph_name, 'graph')\n",
    "    adjacency = nx.adjacency_matrix(G, weight=None)\n",
    "    core = CoreDecomposition()\n",
    "    labels = core.fit_transform(adjacency)\n",
    "    coreness_list = [0 for _ in range(n)]\n",
    "    for i, v in enumerate(iter_nodes(G)):\n",
    "        coreness_list[v] = labels[i]\n",
    "    save_data(coreness_list, graph_name, 'coreness_list')\n",
    "    edges = load_data(graph_name, 'edges')\n",
    "    edge_coreness_list = []\n",
    "    for u, v in edges:\n",
    "        cu, cv = coreness_list[u], coreness_list[v]\n",
    "        edge_coreness_list.append(min(cu, cv))\n",
    "    save_data(edge_coreness_list, graph_name, 'edge_coreness_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "\n",
    "# local path\n",
    "\n",
    "if '9-edge_weight' not in str(Path.cwd()):\n",
    "    os.chdir('9-edge_weight')\n",
    "\n",
    "metrics = [\n",
    "    'LP',\n",
    "]\n",
    "data_names = [\n",
    "    f'{metric}-list' for metric in metrics\n",
    "]\n",
    "for data_name in data_names:\n",
    "    p[data_name] = p_data / data_name\n",
    "    p[data_name].mkdir(exist_ok=True)\n",
    "\n",
    "for graph_name in graphs_sorted_m:\n",
    "    n, m = g2nm[graph_name]\n",
    "    G = load_data(graph_name, 'graph')\n",
    "    edges = load_data(graph_name, 'edges')\n",
    "    number_of_CNs_list = load_data(graph_name, 'number_of_CNs_list')\n",
    "    neighbors_list = load_data(graph_name, 'neighbors_list')\n",
    "    CN_list = load_data(graph_name, 'CN_list')\n",
    "    LP_list = []\n",
    "    epsilon = 0.001\n",
    "    for i, (u, v) in enumerate(tqdm(edges)):\n",
    "        LP_uv = 1. + CN_list[i]\n",
    "        Nu, Nv = neighbors_list[u], neighbors_list[v]\n",
    "        for x, y in product(Nu, Nv):\n",
    "            if x == y:\n",
    "                continue\n",
    "            if y in neighbors_list[x]:\n",
    "                LP_uv += epsilon\n",
    "        LP_list.append(LP_uv)\n",
    "    save_data(LP_list, graph_name, 'LP_list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# local path (using cpp)\n",
    "# you may run the cpp version of the above cell (local_path.cpp) for higher speed\n",
    "# this cell will run the cpp program and read the output\n",
    "\n",
    "# you can change the variable \"graph_names_large\"\n",
    "# for changing the range of the datasets\n",
    "# on which the cpp program runs\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    'LP',\n",
    "]\n",
    "data_names = [\n",
    "    f'{metric}-list' for metric in metrics\n",
    "]\n",
    "for data_name in data_names:\n",
    "    p[data_name] = p_data / data_name\n",
    "    p[data_name].mkdir(exist_ok=True)\n",
    "\n",
    "graph_names_large = graphs_sorted_m\n",
    "# compile the cpp file\n",
    "cmd_compile = ['g++', '-O3', '-std=c++2a', 'local_path.cpp', '-o', 'local_path', '-lpthread']\n",
    "subprocess.run(cmd_compile)\n",
    "for graph_name in graph_names_large:\n",
    "    print(graph_name)\n",
    "    cmd_run = ['./local_path', name2nameShort[graph_name]]\n",
    "    subprocess.run(cmd_run)\n",
    "    for metric in metrics:\n",
    "        metric_list = []\n",
    "        with open(p_data / f'metrics_cpp/{graph_name}_{metric.lower()}.txt') as f:\n",
    "            dd = f.readlines()\n",
    "        for d in dd:\n",
    "            try:\n",
    "                data_float = float(d)\n",
    "                metric_list.append(data_float)\n",
    "            except:\n",
    "                continue\n",
    "        save_data(metric_list, graph_name, f'{metric}-list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# edge betweenness\n",
    "\n",
    "if '9-edge_weight' not in str(Path.cwd()):\n",
    "    os.chdir('9-edge_weight')\n",
    "\n",
    "metric_names = [\n",
    "    'EB',  # edge betweenness\n",
    "]\n",
    "for data_name in data_names:\n",
    "    p[data_name] = p_data / data_name\n",
    "    p[data_name].mkdir(exist_ok=True)\n",
    "\n",
    "for graph_name in graphs_sorted_m:\n",
    "    print(graph_name)\n",
    "    n, m = g2nm[graph_name]\n",
    "    G = load_data(graph_name, 'graph')\n",
    "    edges = load_data(graph_name, 'edges')\n",
    "    e2btwness = nx.edge_betweenness_centrality(G)\n",
    "    EB_list = []\n",
    "    for i, e in enumerate(tqdm(edges)):\n",
    "        u, v = e\n",
    "        try:\n",
    "            EB_list.append(e2btwness[e])\n",
    "        except:\n",
    "            EB_list.append(e2btwness[(v, u)])\n",
    "    save_data(EB_list, graph_name, 'EB-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# edge betweenness (using cpp)\n",
    "# you may run the cpp version of the above cell (eb.cpp) for higher speed\n",
    "# this cell will run the cpp program and read the output\n",
    "\n",
    "# you can change the variable \"graph_names_large\"\n",
    "# for changing the range of the datasets\n",
    "# on which the cpp program runs\n",
    "\n",
    "metrics = [\n",
    "    'EB',\n",
    "]\n",
    "data_names = [f'{metric}-list' for metric in metrics]\n",
    "data_names += [\n",
    "    'edge_txt_BGL',\n",
    "]\n",
    "for data_name in data_names:\n",
    "    p[data_name] = p_data / data_name\n",
    "    p[data_name].mkdir(exist_ok=True)\n",
    "\n",
    "graph_names_large = graphs_sorted_m\n",
    "# compile the cpp file\n",
    "cmd_compile = ['g++', '-O3', '-std=c++2a', 'eb.cpp', '-o', 'eb', '-lpthread']\n",
    "subprocess.run(cmd_compile)\n",
    "for graph_name in graph_names_large:\n",
    "    print(graph_name)\n",
    "    n, m = g2nm[graph_name]\n",
    "    edges = load_data(graph_name, 'edges')\n",
    "    with open(p['edge_txt_BGL'] / f'{graph_name}.edge_txt_BGL', 'w+') as f:\n",
    "        f.write(f'{2 * m}\\n')\n",
    "        for u, v in edges:\n",
    "            f.write(f'{u} - {v}\\n')\n",
    "            f.write(f'{v} - {u}\\n')\n",
    "    cmd_run = ['./eb', name2nameShort[graph_name]]\n",
    "    subprocess.run(cmd_run)\n",
    "    norm_term = n * (n - 1) / 2\n",
    "    with open(p_data / f'metrics_cpp/{graph_name}_eb.txt') as f:\n",
    "        dd = f.readlines()\n",
    "    e2eb = dict()\n",
    "    for d in dd:\n",
    "        u, v, eb = d.split()\n",
    "        u, v, eb = int(u), int(v), float(eb)\n",
    "        e2eb[min_max_tuple(u, v)] = eb\n",
    "    edges = load_data(graph_name, 'edges')\n",
    "    EB_list = []\n",
    "    for i, e in enumerate(tqdm(edges)):\n",
    "        u, v = e\n",
    "        try:\n",
    "            EB_list.append(e2eb[e] / norm_term)\n",
    "        except:\n",
    "            EB_list.append(e2eb[(v, u)] / norm_term)\n",
    "    save_data(EB_list, graph_name, 'EB-list')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
